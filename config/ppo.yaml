# This file is used to configure logging and agents behaviour.
#
# The first part consists of Wandb info used to log experiments.
# Changing it adjusts the way logging is stored and displayed.
#
# The second part (config) is used to change hyperparameter settings of agents.
# Changing it adjusts the way agents behave and learn.
project: "ReinforcementLearning"
name: "PPO PoleBalancing-v1 TV EPS"
dir: "../logs"
notes: "Testing PPO with zero terminal value if episode is terminated and 1e-5 eps for optimizer."
mode: "online"
monitor_gym: "False"
config:
  environment: "PoleBalancing-v1"
  episodes: 500
  max_steps: 500
  gamma: 0.99
  lambda: 0.95
  ppo_epochs: 8
  batch_size: 2048
  clip_epsilon: 0.2
  learning_rate_shared: 0.0005
  learning_rate_actor: 0.0005
  learning_rate_critic: 0.001
  value_loss_coef: 0.5
  entropy_coef: 0.01
